{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH-Q4IrYPkQP",
        "outputId": "e49f640e-4656-4b1d-e219-aab9a27cf24b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1FD6Z3frU3W",
        "outputId": "79bf9e35-833c-4607-9261-1c729bda1cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yvwXw25rRrP",
        "outputId": "b7887ff4-8bfa-46f7-b2f7-af94609954a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xLAERTrAvt_P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import plotly\n",
        "import plotly.figure_factory as ff\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data.distributed\n",
        "from torchvision import transforms\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnnR8VHf5xWT"
      },
      "source": [
        "Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9g58AlEyBijK"
      },
      "outputs": [],
      "source": [
        "#Taken inspiration from - Data processing for nyudepth dataset - referenced  https://arxiv.org/pdf/2210.09071.pdf for preprocessing\n",
        "class NewDataLoader(torch.utils.data.Dataset):\n",
        "  def __init__(self, args, mode,transform=None,filename=None):\n",
        "\n",
        "    self.do_kb_crop = False\n",
        "    self.input_height = 480\n",
        "    self.input_width = 640\n",
        "    self.do_random_rotate = True\n",
        "    self.degree = 2.5\n",
        "    self.transform = transform\n",
        "    self.filenames = None\n",
        "\n",
        "    filename = filename\n",
        "    with open(filename, 'r') as f:\n",
        "        self.filenames = f.readlines()\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    if mode =='train':\n",
        "\n",
        "      sample_path = self.filenames[idx]\n",
        "      rgb_file = sample_path.split()[0]\n",
        "      depth_file = sample_path.split()[1]\n",
        "\n",
        "      image_path = rgb_file\n",
        "      depth_path = depth_file\n",
        "      image = Image.open(image_path)\n",
        "      depth_gt = Image.open(depth_path)\n",
        "\n",
        "\n",
        "      if self.input_height == 480:\n",
        "        depth_gt = np.array(depth_gt)\n",
        "        # print(\"Depth gt\",depth_gt)\n",
        "        valid_mask = np.zeros_like(depth_gt)\n",
        "        valid_mask[45:472, 43:608] = 1\n",
        "        depth_gt[valid_mask==0] = 0\n",
        "        depth_gt = Image.fromarray(depth_gt)\n",
        "      else:\n",
        "        depth_gt = depth_gt.crop((43, 45, 608, 472))\n",
        "        image = image.crop((43, 45, 608, 472))\n",
        "\n",
        "      if self.do_random_rotate is True:\n",
        "                random_angle = (random.random() - 0.5) * 2 * self.degree\n",
        "                image = self.rotate_image(image, random_angle)\n",
        "                depth_gt = self.rotate_image(depth_gt, random_angle, flag=Image.NEAREST)\n",
        "                # depth_gt.show()\n",
        "            \n",
        "      image = np.asarray(image, dtype=np.float32) / 255.0\n",
        "      depth_gt = np.asarray(depth_gt, dtype=np.float32)\n",
        "      depth_gt = np.expand_dims(depth_gt, axis=2)\n",
        "\n",
        "      depth_gt = depth_gt / 1000.0\n",
        "      img, depth = image, depth_gt\n",
        "\n",
        "      \n",
        "      H, W = img.shape[0], img.shape[1]\n",
        "      a, b, c, d = random.uniform(0,1), random.uniform(0,1), random.uniform(0,1), random.uniform(0,1)\n",
        "      l, u = int(a*W), int(b*H)\n",
        "      w, h = int(max((W-a*W)*c*0.75, 1)), int(max((H-b*H)*d*0.75, 1))\n",
        "      depth_copied = np.repeat(depth, 3, axis=2)\n",
        "      M = np.ones(img.shape)\n",
        "      M[l:l+h, u:u+w, :] = 0\n",
        "      img = M*img + (1-M)*depth_copied\n",
        "      image = img.astype(np.float32)\n",
        "\n",
        "\n",
        "      if image.shape[0] != self.input_height or image.shape[1] != self.input_width:\n",
        "          image, depth_gt = self.random_crop(image, depth_gt, self.input_height, self.input_width)\n",
        "      image, depth_gt = self.train_preprocess(image, depth_gt)\n",
        "      sample = {'image': image, 'depth': depth_gt}\n",
        "\n",
        "      if self.transform:\n",
        "          sample = self.transform(sample)\n",
        "      \n",
        "      return sample\n",
        "\n",
        "  def rotate_image(self, image, angle, flag=Image.BILINEAR):\n",
        "        result = image.rotate(angle, resample=flag)\n",
        "        return result\n",
        "\n",
        "  def train_preprocess(self, image, depth_gt):\n",
        "        # Random flipping\n",
        "        do_flip = random.random()\n",
        "        if do_flip > 0.5:\n",
        "            image = (image[:, ::-1, :]).copy()\n",
        "            depth_gt = (depth_gt[:, ::-1, :]).copy()\n",
        "    \n",
        "        # Random gamma, brightness, color augmentation\n",
        "        do_augment = random.random()\n",
        "        if do_augment > 0.5:\n",
        "            image = self.augment_image(image)\n",
        "    \n",
        "        return image, depth_gt\n",
        "  def augment_image(self, image):\n",
        "        # gamma augmentation\n",
        "        gamma = random.uniform(0.9, 1.1)\n",
        "        image_aug = image ** gamma\n",
        "\n",
        "        brightness = random.uniform(0.75, 1.25)\n",
        "        image_aug = image_aug * brightness\n",
        "        colors = np.random.uniform(0.9, 1.1, size=3)\n",
        "        white = np.ones((image.shape[0], image.shape[1]))\n",
        "        color_image = np.stack([white * colors[i] for i in range(3)], axis=2)\n",
        "        image_aug *= color_image\n",
        "        image_aug = np.clip(image_aug, 0, 1)\n",
        "\n",
        "        return image_aug\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oNpKnJIZOyuv"
      },
      "outputs": [],
      "source": [
        "class ToTensor(object):\n",
        "    def __init__(self, mode):\n",
        "        self.mode = mode\n",
        "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    def to_tensor(self, pic):\n",
        "        if isinstance(pic, np.ndarray):\n",
        "            img = torch.from_numpy(pic.transpose((2, 0, 1)))\n",
        "            return img\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image = sample['image']\n",
        "        image = self.to_tensor(image)\n",
        "        image = self.normalize(image)\n",
        "        depth = sample['depth']\n",
        "        if self.mode == 'train':\n",
        "            depth = self.to_tensor(depth)\n",
        "            return {'image': image, 'depth': depth}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-qz8Emw50Id"
      },
      "source": [
        "Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DKZLr7grOAlJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "def preprocessing_transforms(mode):\n",
        "    return transforms.Compose([\n",
        "        ToTensor(mode=mode)\n",
        "    ])\n",
        "mode = 'train'\n",
        "batch_size = 512\n",
        "train_sampler = None\n",
        "train_file = 'train_values.txt'\n",
        "test_file = 'test_values.txt'\n",
        "training_samples = NewDataLoader([], mode, transform=preprocessing_transforms(mode),filename=train_file)\n",
        "testing_samples = NewDataLoader([], mode, transform=preprocessing_transforms(mode),filename=test_file)\n",
        "train_data = DataLoader(training_samples, batch_size,\n",
        "                                   shuffle=(train_sampler is None),\n",
        "                                   num_workers=1,\n",
        "                                   pin_memory=True,\n",
        "                                   sampler=train_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJemW0RG51-s"
      },
      "source": [
        "Loss Implementations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wDw5jDwQJvzr"
      },
      "outputs": [],
      "source": [
        "#used to calculate the silog loss\n",
        "class silog_loss(nn.Module):\n",
        "    def __init__(self, vf):\n",
        "        super(silog_loss, self).__init__()\n",
        "        self.vf = vf #variance_focus\n",
        "\n",
        "    def forward(self, depth_est, depth_gt,mask):\n",
        "        d = torch.log(depth_est[mask]) - torch.log(depth_gt[mask])\n",
        "        return torch.sqrt((d ** 2).mean() - self.vf * (d.mean() ** 2)) * 10.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "maBbCkq88Yxe"
      },
      "outputs": [],
      "source": [
        "#used to calculate the huber loss\n",
        "class HuberLoss(nn.Module):\n",
        "    def __init__(self, delta=1.0):\n",
        "        super(HuberLoss, self).__init__()\n",
        "        self.delta = delta\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        residual = torch.abs(y_true - y_pred)\n",
        "        condition = residual < self.delta\n",
        "        loss = torch.where(condition, 0.5 * residual ** 2, self.delta * residual - 0.5 * self.delta ** 2)\n",
        "        return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lrv0R6QE_Y0Y"
      },
      "outputs": [],
      "source": [
        "#used to calculate the berlu loss\n",
        "def berhu_loss(pred, target, threshold=0.2):\n",
        "    diff = torch.abs(target - pred)\n",
        "    delta = threshold * torch.max(target).item()\n",
        "    mask = (diff < delta).float()\n",
        "    loss = mask * (diff ** 2 / delta) \n",
        "    loss+= (1 - mask) * (diff - 0.5 * delta)\n",
        "    return torch.mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIlWl3vM54En"
      },
      "source": [
        "Error computations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qDFrD2kqkAGt"
      },
      "outputs": [],
      "source": [
        "def compute_errors(gt, pred):\n",
        "\n",
        "    abs_diff = np.abs(gt - pred)\n",
        "    # d1_error = abs_diff > (1.25)\n",
        "\n",
        "    d1 = 0\n",
        "    rms = (gt - pred) ** 2\n",
        "    rms = np.sqrt(torch.mean(rms))\n",
        "    log_rms = (np.log(gt) - np.log(pred)) ** 2\n",
        "    log_rms = np.sqrt(torch.mean(log_rms))\n",
        "\n",
        "    abs_rel = torch.mean(np.abs(gt - pred) / gt)\n",
        "    sq_rel = torch.mean(((gt - pred) ** 2) / gt)\n",
        "    \n",
        "    err = np.log(pred) - np.log(gt)\n",
        "    err = np.abs(np.log10(pred) - np.log10(gt))\n",
        "    log10 = torch.mean(err)\n",
        "    # print(\"RMS\",log10)\n",
        "\n",
        "    return [ abs_rel, log10, rms, sq_rel, log_rms, d1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQl_i_lf57uA"
      },
      "source": [
        "Defining the Base ResNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "E7qkjghcV0p6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "#used layer norm instead of batch norm due to batch_size =1 \n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.LayerNorm(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.LayerNorm(out_channels)\n",
        "        self.residual_change_conv  = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "        self.residual_change_ln =  nn.LayerNorm(out_channels)\n",
        "\n",
        "        self.change_channels = nn.Conv2d(64, 3, kernel_size=1)\n",
        "\n",
        "        self.conv_operation = nn.Conv2d(in_channels=3,out_channels=1,kernel_size=1).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.conv1(x)\n",
        "        x = x.permute(0,2,3,1)\n",
        "\n",
        "        x = self.bn1(x)\n",
        "        x = x.permute(0,3,1,2)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.permute(0,2,3,1)\n",
        "\n",
        "        x = self.bn2(x)\n",
        "        x = x.permute(0,3,1,2)\n",
        "        residual = self.residual_change_conv(residual)\n",
        "        residual = residual.permute(0,2,3,1)\n",
        "        # print(\"Hi\",x.shape)\n",
        "        residual = self.residual_change_ln(residual)\n",
        "        residual = residual.permute(0,3,1,2)\n",
        "        x += residual\n",
        "        x = self.relu(x)\n",
        "        out = self.change_channels(x)\n",
        "        out = self.conv_operation(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayd6T2oS5_k3"
      },
      "source": [
        "Training and Validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPXy6mi3Ux_A"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "variance_focus = 0.05\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10\n",
        "# batch_size = len(training_samples)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "#declaring the resnet model\n",
        "model = ResNetBlock(in_channels=3,out_channels=64).to(device)\n",
        "conv_operation = nn.Conv2d(in_channels=3,out_channels=1,kernel_size=1).to(device)\n",
        "\n",
        "num_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
        "print(\"== Total number of parameters: {}\".format(num_params))\n",
        "num_params_update = sum([np.prod(p.shape) for p in model.parameters() if p.requires_grad])\n",
        "print(\"== Total number of learning parameters: {}\".format(num_params_update))\n",
        "\n",
        "optimizer = torch.optim.Adam([{'params': model.parameters()}],lr=learning_rate)\n",
        "\n",
        "#loss\n",
        "silog_criterion = silog_loss(vf=variance_focus)\n",
        "huber_loss = HuberLoss(delta=0.5)\n",
        "\n",
        "\n",
        "#epoch runs\n",
        "for epoch in range(num_epochs):\n",
        "  checkpoint_path = \"checkpoint_resnet\"+str(epoch)+\".pt\"\n",
        "  train_loss = 0\n",
        "  #running for training_samples\n",
        "  for train_val in training_samples:\n",
        "    #putting model in train mode\n",
        "    model.train()\n",
        "    #initializing optimizer to zero\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #converting image and target depth to torch variable\n",
        "    image = torch.autograd.Variable(train_val['image']) #gpu\n",
        "    depth_gt = torch.autograd.Variable(train_val['depth'])\n",
        "    # print(\"DEPTHHHH\",depth_gt.shape)\n",
        "\n",
        "    #unsqueeze to get correct structure\n",
        "    image = image.unsqueeze(0).to(device)\n",
        "    depth_gt = depth_gt.unsqueeze(0).to(device)\n",
        "\n",
        "    #passing through model for training\n",
        "    resnet_image = model(image)\n",
        "    depth_est = resnet_image\n",
        "\n",
        "    #conv operation for channel updation\n",
        "    # depth_est = conv_operation(depth_est)\n",
        "\n",
        "    #done to remove 0 log error\n",
        "    mask =  (depth_est>0.1) & (depth_gt>0.1) \n",
        "    \n",
        "    #losses\n",
        "    # l1 = silog_criterion.forward(depth_est,depth_gt,mask.to(torch.bool))\n",
        "    l1 = huber_loss(depth_est[mask],depth_gt[mask])\n",
        "    # l1 = berhu_loss(depth_est,depth_gt)\n",
        "\n",
        "    #updating loss\n",
        "    train_loss+=l1\n",
        "    l1.backward()\n",
        "    optimizer.step()\n",
        "    # print(\"Train loss\",l1)\n",
        "  # model.load_state_dict(torch.load('resnet_just/checkpoint12.pt',map_location=torch.device('cpu')))\n",
        "  #turning to eval mode\n",
        "  val_loss = 0.0\n",
        "  val_acc = 0.0\n",
        "  # Iterate over the validation dataset\n",
        "\n",
        "  #intialize the error values\n",
        "  rae ,log10 , rms, sql_rel, log_rms, d1 = 0,0,0,0,0,0\n",
        "  with torch.no_grad():\n",
        "    for val in testing_samples:\n",
        "        image = torch.autograd.Variable(val['image'])\n",
        "        depth_gt = torch.autograd.Variable(val['depth']) #gpu\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "        depth_gt = depth_gt.unsqueeze(0).to(device)\n",
        "        resnet_image = model.eval()(image)\n",
        "        depth_est = resnet_image\n",
        "        # depth_est = conv_operation(resnet_image)\n",
        "        mask =  (depth_est>0.1) & (depth_gt>0.1)\n",
        "        # loss = silog_criterion.forward(depth_est, depth_gt,mask.to(torch.bool))\n",
        "        loss = huber_loss(depth_est[mask],depth_gt[mask])\n",
        "        # loss = berhu_loss(depth_est,depth_gt)\n",
        "        # print(loss)\n",
        "        val_loss += loss.item() \n",
        "        # Compute the errors\n",
        "        erros_measures = compute_errors(depth_est[mask.to(torch.bool)].cpu(),depth_gt[mask.to(torch.bool)].cpu())\n",
        "        rae += erros_measures[0]\n",
        "        log10 += erros_measures[1]\n",
        "        rms += erros_measures[2]\n",
        "        # sql_rel += erros_measures[3]\n",
        "        log_rms += erros_measures[4]\n",
        "        # d1 += erros_measures[5]\n",
        "    print(\"Average error measures for val dataset:\")\n",
        "    print(\"Absolute error {:.4f} Log10 {:.4f} RMS {:.4f} log_rms {:.4f}\".format(rae/len(testing_samples),log10/len(testing_samples),rms/len(testing_samples),log_rms/len(testing_samples)))\n",
        "  \n",
        "  # Compute the average validation loss and accuracy\n",
        "  val_loss /= len(testing_samples)\n",
        "  train_loss /=len(training_samples)\n",
        "\n",
        "  #save checkpoint for each epoch\n",
        "  torch.save(model.state_dict(),checkpoint_path)\n",
        "    \n",
        "  # Print the epoch number, training loss, and validation loss and accuracy\n",
        "  print(\"Epoch {}: train_loss {:.4f} val_loss {:.4f}\".format(epoch+1, train_loss, val_loss))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uQsuXURXmr-"
      },
      "source": [
        "Testing Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88L9wgObWSZ4",
        "outputId": "1c5a540e-0044-42d2-b24b-7e7c4390aab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Total number of parameters: 39367\n",
            "== Total number of learning parameters: 39367\n",
            "ResNetBlock(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "  (residual_change_conv): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (residual_change_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "  (change_channels): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv_operation): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Average error measures for val dataset:\n",
            "Absolute error 0.4183 Log10 0.1582 RMS 1.2006 log_rms 0.4339\n",
            " val_loss 0.3679\n"
          ]
        }
      ],
      "source": [
        "# Training parameters\n",
        "variance_focus = 0.05\n",
        "learning_rate = 0.01\n",
        "num_epochs = 20\n",
        "# batch_size = len(training_samples)\n",
        "torch.manual_seed(42)\n",
        "#declaring the resnet model\n",
        "model = ResNetBlock(in_channels=3,out_channels=64).to(device)\n",
        "conv_operation = nn.Conv2d(in_channels=3,out_channels=1,kernel_size=1).to(device)\n",
        "\n",
        "num_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
        "print(\"== Total number of parameters: {}\".format(num_params))\n",
        "num_params_update = sum([np.prod(p.shape) for p in model.parameters() if p.requires_grad])\n",
        "print(\"== Total number of learning parameters: {}\".format(num_params_update))\n",
        "\n",
        "optimizer = torch.optim.Adam([{'params': model.parameters()}],lr=learning_rate)\n",
        "\n",
        "#loss\n",
        "silog_criterion = silog_loss(vf=variance_focus)\n",
        "huber_loss = HuberLoss(delta=0.5)\n",
        "\n",
        "model.load_state_dict(torch.load('checkpoint_resnet.pt',map_location=torch.device('cpu')))\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(model)\n",
        "model.eval()\n",
        "val_loss = 0.0\n",
        "rae ,log10 , rms, sql_rel, log_rms, d1 = 0,0,0,0,0,0\n",
        "with torch.no_grad():\n",
        "  for val in testing_samples:\n",
        "      image = torch.autograd.Variable(val['image'])\n",
        "      depth_gt = torch.autograd.Variable(val['depth']) #gpu\n",
        "      image = image.unsqueeze(0).to(device)\n",
        "      depth_gt = depth_gt.unsqueeze(0).to(device)\n",
        "      # print(image.shape)\n",
        "      resnet_image = model(image)\n",
        "      depth_est = resnet_image\n",
        "      # depth_est = conv_operation(resnet_image)\n",
        "      mask =  (depth_est>0.1) & (depth_gt>0.1)\n",
        "      # print(mask)\n",
        "      # loss = silog_criterion.forward(depth_est, depth_gt,mask.to(torch.bool))\n",
        "      loss = huber_loss(depth_est[mask],depth_gt[mask])\n",
        "      # loss = berhu_loss(depth_est,depth_gt)\n",
        "      val_loss += loss.item()\n",
        "      # print(val_loss) \n",
        "      # Compute the errors\n",
        "      erros_measures = compute_errors(depth_est[mask.to(torch.bool)].cpu(),depth_gt[mask.to(torch.bool)].cpu())\n",
        "      rae += erros_measures[0]\n",
        "      log10 += erros_measures[1]\n",
        "      rms += erros_measures[2]\n",
        "      # sql_rel += erros_measures[3]\n",
        "      log_rms += erros_measures[4]\n",
        "      # d1 += erros_measures[5]\n",
        "  print(\"Average error measures for val dataset:\")\n",
        "  print(\"Absolute error {:.4f} Log10 {:.4f} RMS {:.4f} log_rms {:.4f}\".format(rae/len(testing_samples),log10/len(testing_samples),rms/len(testing_samples),log_rms/len(testing_samples)))\n",
        "\n",
        "# Compute the average validation loss and accuracy\n",
        "val_loss /= len(testing_samples)\n",
        "# train_loss /=len(training_samples)\n",
        "  \n",
        "# Print the epoch number, training loss, and validation loss and accuracy\n",
        "print(\" val_loss {:.4f}\".format( val_loss))\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
